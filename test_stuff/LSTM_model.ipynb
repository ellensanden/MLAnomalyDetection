{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd091765243d447bc10b34282cff786081469c78a527bea45126a87448256c6538f",
   "display_name": "Python 3.8.5 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## LSTM AUTOENCODER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "colnames = [\"time\", \"ID\", \"DLC\", \"Data1\", \\\n",
    "        \"Data2\", \"Data3\", \"Data4\", \"Data5\", \"Data6\", \"Data7\", \"Data8\", \"Attack\"]\n",
    "\n",
    "nRows = 100000 #number of rows that you want\n",
    "df = pd.read_csv('gear_dataset.csv', nrows = nRows, sep=',', names=colnames)\n",
    "#df = pd.read_csv('gear_dataset.csv', sep=',', names=colnames)\n",
    "\n",
    "uniqueIDs = df['ID'].unique() #26 for the entire dataset\n",
    "\n",
    "#Drop attack packets\n",
    "attack = df[df['Attack'] == 'T'].copy()\n",
    "df.drop(attack.index, axis=0, inplace=True)\n",
    "\n",
    "#Drop DLC = 2 packets\n",
    "dlc2 = df[df['DLC'] == 2]\n",
    "df.drop(dlc2.index, axis=0, inplace=True) #drop all dlc2 indexes\n",
    "\n",
    "#Pick an ID\n",
    "#id_data= df[df['ID'] == '0140'].copy()\n",
    "id_data = df # to use all ids\n",
    "#Just use data values without time, Attack, ID and DLC right now\n",
    "dataValues = id_data.drop([\"time\", \"Attack\", \"ID\", \"DLC\"], axis = 1).copy()\n",
    "#dataValues.to_csv (r'one_id.csv', index=None)\n",
    "\n",
    "dataValues = dataValues.to_numpy()\n",
    "\n",
    "\n",
    "storage = np.zeros((len(dataValues),64), dtype=int)\n",
    "for currentRow in np.arange(len(storage)):\n",
    "    \n",
    "    tempString = \"\".join(dataValues[currentRow])\n",
    "    formatted = format(int(tempString, base=16), \"064b\")\n",
    "    storage[currentRow,:] = np.array(list(formatted), dtype=int)\n",
    "\n",
    "\n",
    "n_rows = storage.shape[0]\n",
    "n_features = storage.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from numpy import array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_window (window_size,overlap,seq): # overlap 1 is max. larger number would be less overlap\n",
    " \n",
    "    seq = array([seq[i : i + window_size] for i in range(0, len(seq), overlap)]) \n",
    "   \n",
    "    correct = [len(x)==window_size for x in seq]\n",
    "    seq = seq[correct]\n",
    "    seq = np.stack(seq, axis=0 )\n",
    "    seq = seq.reshape(-1,window_size,1)\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 40\n",
    "a = np.r_[0:n_rows]\n",
    "\n",
    "X_train_samples = overlapping_window(time_steps,20,a)\n",
    "X_train = storage[X_train_samples,:]\n",
    "X_train = np.squeeze(X_train)\n",
    "# print(X_train.shape)\n",
    "\n",
    "X_reversed = np.flip(X_train,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X_train.shape[0]\n",
    "time_steps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "\n",
    "lstm_initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5)\n",
    "\n",
    "encoderLSTM = LSTM(128,return_sequences=True,kernel_initializer =lstm_initializer, recurrent_initializer=lstm_initializer)\n",
    "\n",
    "# define Encoder\n",
    "EncoderInputs = Input(shape=(time_steps,n_features))\n",
    "dense1 =Dense(256, activation='tanh')(EncoderInputs)\n",
    "dropout = Dropout(0.2)(dense1)\n",
    "lstm1 = encoderLSTM(dropout)\n",
    "lstm2, state_h, state_c = LSTM(128,return_sequences=True,return_state=True,kernel_initializer =lstm_initializer, recurrent_initializer=lstm_initializer)(lstm1)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# define Decoder\n",
    "lstm3 =  LSTM(128,return_sequences=True,kernel_initializer =lstm_initializer, recurrent_initializer=lstm_initializer)(lstm2,initial_state=encoder_states)\n",
    "lstm4 = LSTM(128,return_sequences=True,kernel_initializer =lstm_initializer, recurrent_initializer=lstm_initializer)(lstm3)\n",
    "dense2 = Dense(256, activation='sigmoid')(lstm4)\n",
    "output = Dense(n_features,activation= 'sigmoid')(dense2)\n",
    "\n",
    "EncoderDecoder = Model(inputs=EncoderInputs, outputs=output,name=\"EncoderDecoder\")\n",
    "EncoderDecoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "EncoderDecoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "train_size = int(np.floor(0.7*n_samples))\n",
    "\n",
    "model = EncoderDecoder\n",
    "es= EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "\n",
    "s=time.time()\n",
    "\n",
    "history = model.fit(X_train[0:train_size,:,:], X_train[0:train_size,:,:], validation_data=(X_train[train_size:,:,:], X_train[train_size:,:,:]), epochs=300, verbose=2, shuffle=False, callbacks = [es])\n",
    "\n",
    "e=time.time()\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='validation')\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "print(f'training time = {e-s} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}