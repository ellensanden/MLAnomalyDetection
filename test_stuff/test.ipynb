{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Import and format data\n",
    "## These  (until *) don't need to be run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# names = ['Time','ID','Data']\n",
    "read_file = pd.read_csv(\"candump-2021-02-08_150302.log\", header = None)\n",
    "read_file.to_csv (r'can_data.csv', index=None)\n",
    "can_data = pd.read_csv(\"can_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_data"
   ]
  },
  {
   "source": [
    "### remove vcan0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"can_data.csv\", \"r\")\n",
    "text = ''.join([i for i in text]) \\\n",
    "    .replace(\"vcan0\", \",\")\n",
    "x = open(\"can_data.csv\",\"w\")\n",
    "x.writelines(text)\n",
    "x.close()"
   ]
  },
  {
   "source": [
    "### remove hash"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"can_data.csv\", \"r\")\n",
    "text = ''.join([i for i in text]) \\\n",
    "    .replace(\"#\", \",\")\n",
    "x = open(\"can_data.csv\",\"w\")\n",
    "x.writelines(text)\n",
    "x.close()"
   ]
  },
  {
   "source": [
    "### remove parenthesis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"can_data.csv\", \"r\")\n",
    "text = ''.join([i for i in text]) \\\n",
    "    .replace(\"(\", \"\")\n",
    "x = open(\"can_data.csv\",\"w\")\n",
    "x.writelines(text)\n",
    "x.close()\n",
    "\n",
    "text = open(\"can_data.csv\", \"r\")\n",
    "text = ''.join([i for i in text]) \\\n",
    "    .replace(\")\", \"\")\n",
    "x = open(\"can_data.csv\",\"w\")\n",
    "x.writelines(text)\n",
    "x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_data = pd.read_csv(\"can_data.csv\",names = ['Time','ID','Data'])\n",
    "can_data.to_csv (r'can_data.csv', index=None)\n",
    "print(can_data)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# *"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "can_data = pd.read_csv(\"can_data.csv\")\n",
    "print(can_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time = can_data['Time']\n",
    "Time = Time[1:-1]\n",
    "Time = Time.reset_index(drop=True)\n",
    "\n",
    "ID = can_data['ID']\n",
    "ID = ID[1:-1]\n",
    "ID = ID.reset_index(drop=True)\n",
    "\n",
    "Data = can_data['Data']\n",
    "Data = Data[1:-1]\n",
    "Data = Data.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def delta_time(Time): # calculates the time between two subsequent messages\n",
    "    delta = np.zeros((Time.size))\n",
    "    for x in range(Time.size-1):\n",
    "\n",
    "       delta[x] = Time[x+1]-Time[x]\n",
    "\n",
    "    return delta   \n",
    "\n",
    "delta = delta_time(Time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def convert_from_hex(hex,output_type): # converts the data in hex from hexadecimal to decimal form\n",
    "     out = np.zeros((hex.size))\n",
    "     if output_type == 'dec':\n",
    "        for x in range(hex.size):\n",
    "            h_value = hex[x]\n",
    "            out[x] = int(h_value,16)\n",
    "     else:\n",
    "        for x in range(hex.size):\n",
    "            h_value = hex[x]\n",
    "            binary[x] = bin(int(h_value, 16))[2:]\n",
    "\n",
    "     return out\n",
    "\n",
    "\n",
    "data = convert_from_hex(Data,'dec')\n",
    "id = convert_from_hex(ID,'dec')"
   ]
  },
  {
   "source": [
    "## Normalize data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = data.reshape(-1, 1)\n",
    "#data = scaler.fit_transform(data)\n",
    "id = id.reshape(-1, 1)\n",
    "id = scaler.fit_transform(id)"
   ]
  },
  {
   "source": [
    "## Visualize data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Time[0:10000],data[0:10000],'o')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Data')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(Time[0:10000],id[0:10000],'o')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('ID')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data[0:10000],id[0:10000],'o')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('ID')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = range(Time.size)\n",
    "plt.figure()\n",
    "plt.plot(steps[0:100000],delta[0:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_IDs(id): # returns groups of indices of unique ids in list \n",
    "\n",
    "    idx_sort = np.argsort(id)\n",
    "    sorted_ids = id[idx_sort]\n",
    "    vals, idx_start, count = np.unique(sorted_ids, return_counts=True, return_index=True)\n",
    "    indices = np.split(idx_sort, idx_start[1:])\n",
    "\n",
    "    return indices\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_id = np.transpose(id) # not sure why it needs to be transposed but it doesn't work otherwise\n",
    "indices = sort_IDs(transposed_id[0][:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_stream(indices,data): # collects the unique ids with their respective data streams\n",
    "\n",
    "    num_unique_ids = len(indices)\n",
    "    all_ids = []\n",
    "    for x in range(num_unique_ids):\n",
    "         \n",
    "         id_data = data[indices[x]]\n",
    "         all_ids.append(id_data)\n",
    "\n",
    "    return all_ids\n",
    "\n",
    "all_id_data = get_data_stream(indices,data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # combines each unique id with its data stream in a matrix where the ID is in the first row, and its data stream is (ordered)\n",
    " # in the column under it. (one column = ID: data1,data2,..). column length = max data length, if data doesn't fill upp all rows they are filled with nan. \n",
    "def combine_ids_data(indices,id,all_id_data):\n",
    "    i = -1\n",
    "    ids_and_data = np.ones((np.max([len(pi) for pi in all_id_data])+1,len(all_id_data)))*np.nan \n",
    "\n",
    "    for x in indices:\n",
    "        i = i+ 1\n",
    "        index = indices[i] \n",
    "        index = index[0] # only save first one in group\n",
    "        ID = id[index]\n",
    "\n",
    "        data_stream = all_id_data[i]\n",
    "        data_stream = data_stream[:,0] \n",
    "        ids_and_data[0,i] = ID\n",
    "        ids_and_data[1:len(data_stream)+1,i] = data_stream\n",
    "\n",
    "    return ids_and_data\n",
    "\n",
    "d = combine_ids_data(indices,id,all_id_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Number of individual IDs in the full sequence = {len(d[0,:])}')\n",
    "print(f'Maximum number of data packets per ID = {np.max([len(pi) for pi in all_id_data])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(100),d[0:100,0],'-o')"
   ]
  },
  {
   "source": [
    "# Copied"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "from numpy import array\n",
    "\n",
    "\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans(input): # remove nans from data stream column\n",
    "    input_nans = np.isnan(input) \n",
    "    not_nan = ~ input_nans\n",
    "    clean_input = input[not_nan]\n",
    "    return clean_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        end_iy = end_ix + n_steps \n",
    "\t\t# check if we are beyond the sequence\n",
    "        if end_iy > len(sequence)-1:\n",
    "            break\n",
    "\t\t# gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_iy]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "seq = remove_nans(d[:,0])   \n",
    "\n",
    "nTrain = round(0.9*len(seq))\n",
    "nTest = len(seq)-nTrain\n",
    "xTrain = seq[0:nTrain]\n",
    "xTest = seq[nTrain:len(seq)]\n",
    "\n",
    "X_train, y_train = split_sequence(xTrain, n_steps)\n",
    "X_test, y_test = split_sequence(xTest, n_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow\n",
    "#! pip install keras\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define model (autoencoder)\n",
    "n_steps = 5\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_steps,1)))\n",
    "print(model.output_shape)\n",
    "model.add(RepeatVector(n_steps))\n",
    "print(model.output_shape)\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "source": [
    "# CANnolo\n",
    "Will probably need to use the functional API and not the sequential model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# canolo\n",
    "model = Sequential()\n",
    "\n",
    "# Encoder\n",
    "model.add(Dense(256, activation='tanh', input_shape=(n_steps,1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "#model.add(RepeatVector(n_steps))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "#model.add(RepeatVector(n_steps))\n",
    "\n",
    "# Decoder\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "#model.add(RepeatVector(n_steps))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(256, activation= 'sigmoid')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "#model.add(Dense(1)) # they don't mention this in the article but dimensions are wrong otherwise\n",
    "\n",
    "#model.compile(optimizer='adam', loss='BinaryCrossentropy')\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "# define model\n",
    "inputs1 = Input(shape=(3, 1))\n",
    "lstm1 = LSTM(1,return_sequences=True)(inputs1)\n",
    "model = Model(inputs=inputs1, outputs=lstm1)\n",
    "# define input data\n",
    "data = array([0.1, 0.2, 0.3,0.4,0.5,0.6]).reshape((2,3,1))\n",
    "# make and show prediction\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"Encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 3, 1)]            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3, 256)            512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 3, 128)            197120    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               [(None, 3, 128), (None, 1 131584    \n",
      "=================================================================\n",
      "Total params: 329,216\n",
      "Trainable params: 329,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 3, 1)]            0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 3, 128)            66560     \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 3, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3, 256)            33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 3, 1)              257       \n",
      "=================================================================\n",
      "Total params: 231,425\n",
      "Trainable params: 231,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# think i need to loop over prediction or training! \n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "# define input data\n",
    "input_data = array([0.1, 0.2, 0.3,0.4,0.5,0.6]).reshape((2,3,1))\n",
    "time_steps = 3\n",
    "n_samples = 2\n",
    "n_features = 1\n",
    "\n",
    "# define Encoder\n",
    "\n",
    "inputs1 = Input(shape=(time_steps,n_features))\n",
    "dense1 =Dense(256, activation='tanh')(inputs1)\n",
    "dropout = Dropout(0.2)(dense1)\n",
    "lstm1 = LSTM(128,return_sequences=True)(dropout)\n",
    "lstm2, state_h, state_c = LSTM(128,return_sequences=True,return_state=True)(lstm1)\n",
    "states = [state_h, state_c]\n",
    "\n",
    "Encoder = Model(inputs=inputs1, outputs=states,name=\"Encoder\")\n",
    "Encoder.summary()\n",
    "\n",
    "# define Decoder\n",
    "#decoder_input = np.zeros((n_samples,time_steps,n_features))\n",
    "# for _ in range(n_samples):\n",
    "#     #Want to run the decoder on one time window at a time\n",
    "#     lstm3 =  LSTM(128,return_sequences=True)(decoder_input, initial_state=states)\n",
    "#     lstm4 = LSTM(128,return_sequences=True)(lstm3)\n",
    "#     dense2 = Dense(256, activation='sigmoid')(lstm4)\n",
    "#     decoder_input = dense2\n",
    "  \n",
    "decoder_input = Input(shape=(time_steps,n_features))\n",
    "lstm3 =  LSTM(128,return_sequences=True)(decoder_input)\n",
    "lstm4 = LSTM(128,return_sequences=True)(lstm3)\n",
    "dense2 = Dense(256, activation='sigmoid')(lstm4)\n",
    "#decoder_input = dense2\n",
    "\n",
    "output =  TimeDistributed(Dense(1))(dense2)\n",
    "#output = dense2\n",
    "#lstm3 = LSTM(128,return_sequences=True)([lstm2, state_h, state_c])\n",
    "#lstm4, state_h, state_c = LSTM(128,return_sequences=True,return_state=True)(lstm3)\n",
    "#dense2 = Dense(256, activation='sigmoid')(lstm4)\n",
    "\n",
    "#EncoderDecoder = Model(inputs=inputs1, outputs=output,name=\"EncoderDecoder\")\n",
    "Decoder = Model(inputs=decoder_input, outputs=output, name=\"Decoder\")\n",
    "\n",
    "Decoder.summary()\n",
    "\n",
    "#plot_model(EncoderDecoder, to_file='EncoderDecoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(decoder_input,time_steps,n_features):\n",
    "\n",
    "    #define encoder\n",
    "    inputs1 = Input(shape=(time_steps,n_features))\n",
    "    dense1 =Dense(256, activation='tanh')(inputs1)\n",
    "    dropout = Dropout(0.2)(dense1)\n",
    "    lstm1 = LSTM(128,return_sequences=True)(dropout)\n",
    "    lstm2, state_h, state_c = LSTM(128,return_sequences=True,return_state=True)(lstm1)\n",
    "    states = [state_h, state_c]\n",
    "\n",
    "    # define decoder  \n",
    "    #d_input = [decoder_input,lstm2]\n",
    "    #lstm3 =  LSTM(128,return_sequences=True)(decoder_input, initial_state = states) # need to have both decoder input and encoder output as input here\n",
    "    lstm3 =  LSTM(128,return_sequences=True)(lstm2,initial_state=states)\n",
    "    lstm4 = LSTM(128,return_sequences=True)(lstm3)\n",
    "    dense2 = Dense(256, activation='sigmoid')(lstm4)\n",
    "    output =  TimeDistributed(Dense(1))(dense2)\n",
    "\n",
    "\n",
    "    EncoderDecoder = Model(inputs=inputs1, outputs=output,name=\"EncoderDecoder\")\n",
    "    EncoderDecoder.summary()\n",
    "\n",
    "    return EncoderDecoder\n",
    "\n",
    "#plot_model(EncoderDecoder, to_file='EncoderDecoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"EncoderDecoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 5, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 5, 256)       512         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 5, 256)       0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 5, 128)       197120      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  [(None, 5, 128), (No 131584      lstm_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 5, 128)       131584      lstm_25[0][0]                    \n",
      "                                                                 lstm_25[0][1]                    \n",
      "                                                                 lstm_25[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 5, 128)       131584      lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 5, 256)       33024       lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 5, 1)         257         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 625,665\n",
      "Trainable params: 625,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5, 1) for input Tensor(\"input_7:0\", shape=(None, 5, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002738D3A8670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Model: \"EncoderDecoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 5, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 5, 256)       512         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 5, 256)       0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                  (None, 5, 128)       197120      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                  [(None, 5, 128), (No 131584      lstm_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_30 (LSTM)                  (None, 5, 128)       131584      lstm_29[0][0]                    \n",
      "                                                                 lstm_29[0][1]                    \n",
      "                                                                 lstm_29[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 5, 128)       131584      lstm_30[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 5, 256)       33024       lstm_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 5, 1)         257         dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 625,665\n",
      "Trainable params: 625,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5, 1) for input Tensor(\"input_8:0\", shape=(None, 5, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002738EED1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Model: \"EncoderDecoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 5, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 5, 256)       512         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 5, 256)       0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  (None, 5, 128)       197120      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  [(None, 5, 128), (No 131584      lstm_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  (None, 5, 128)       131584      lstm_33[0][0]                    \n",
      "                                                                 lstm_33[0][1]                    \n",
      "                                                                 lstm_33[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  (None, 5, 128)       131584      lstm_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 5, 256)       33024       lstm_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 5, 1)         257         dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 625,665\n",
      "Trainable params: 625,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 5, 1) for input Tensor(\"input_9:0\", shape=(None, 5, 1), dtype=float32), but it was called on an input with incompatible shape (None, 1, 1).\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002739352DC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=1000)\n",
    "time_steps = 5\n",
    "n_samples = 3\n",
    "n_features = 1\n",
    "decoder_input = np.zeros((1,time_steps,n_features))\n",
    "for x in range(n_samples):\n",
    "\n",
    "    X_train = training_data[x,:,:]\n",
    "    X_test = test_data[x,:,:]\n",
    "    y_train = rev_training_data[x,:,:]\n",
    "    y_test = rev_test_data[x,:,:]\n",
    "\n",
    "    model = build_model(decoder_input,time_steps,n_features)\n",
    "    decoder_output = model.predict(X_train)\n",
    "    decoder_input = decoder_output\n",
    "\n",
    "    #train = model.fit(X_train, y_train, epochs=500, batch_size=15, validation_data=(X_test, y_test), verbose=2, shuffle=False,callbacks=[es])\n"
   ]
  },
  {
   "source": [
    "from matplotlib import pyplot\n",
    "# design network\n",
    "# fit network\n",
    "# batch size should be 128\n",
    "model = EncoderDecoder\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=1000)\n",
    "#for x in range(num_samples):\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=15, validation_data=(X_test, y_test), verbose=2, shuffle=False,callbacks=[es])\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-433ce75c02bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# batch size should be 128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoderDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#for x in range(num_samples):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "\n",
    "n_steps = 5\n",
    "nums = array([1,2,3,4,5,6,7,8,9,10,11,12,13,141,5])\n",
    "test_nums = array([1, 1, 1, 2, 6, 2, 4, 2, 3, 8, 7, 6, 2, 3, 14])\n",
    "rev_nums = nums[::-1]\n",
    "rev_test_nums = test_nums[::-1]\n",
    "n_features = 1\n",
    "#X_test = test_nums.reshape((test_nums.shape[0], test_nums.shape[1], n_features))\n",
    "#y_test = rev_test_nums.reshape((rev_test_nums.shape[0], rev_test_nums.shape[1], n_features))\n",
    "#X_train = nums.reshape((nums.shape[0], nums.shape[1], n_features))\n",
    "#y_train = rev_nums.reshape((rev_nums.shape[0], rev_nums.shape[1], n_features))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# nums = nums.reshape(-1, 1)\n",
    "# rev_test_nums = rev_test_nums.reshape(-1,1)\n",
    "# test_nums = test_nums.reshape(-1,1)\n",
    "# rev_nums = rev_nums.reshape(-1,1)\n",
    "\n",
    "# nums = scaler.fit_transform(nums)\n",
    "# rev_nums = scaler.fit_transform(rev_nums)\n",
    "\n",
    "# test_nums = scaler.fit_transform(test_nums)\n",
    "# rev_test_nums = scaler.fit_transform(rev_test_nums)\n",
    "\n",
    "X_test = test_nums.reshape((3, n_steps, n_features))\n",
    "y_test = rev_test_nums.reshape((3, n_steps, n_features))\n",
    "X_train = nums.reshape((3, n_steps, n_features))\n",
    "y_train = rev_nums.reshape((3, n_steps, n_features))\n",
    "\n",
    "training_data = X_train\n",
    "test_data = X_test\n",
    "rev_training_data = y_train\n",
    "rev_test_data = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# demonstrate prediction\n",
    "x_input = array([1,2,3,4,5,6,7,8,9,10,11,12,13,141,5])\n",
    "x_input = x_input.reshape(3,5,1)\n",
    "#print(x_input)\n",
    "#x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(784,))\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "a = dense(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(a)\n",
    "outputs = layers.Dense(10)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Anomaly signal processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction error is calculated using the validation set\n",
    "\n"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "Anomaly score:\n",
    "$a = (e- \\mu)^T \\Sigma ^{-1} (e-\\mu)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}