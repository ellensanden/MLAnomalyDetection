{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd091765243d447bc10b34282cff786081469c78a527bea45126a87448256c6538f",
   "display_name": "Python 3.8.5 64-bit ('tf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## continuously import and evaluate data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"data_processing.py\").read()) # to run the processing file\n",
    "# maybe better to just get the storage variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_processing\n",
    "#data_processing.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while ~isempty(current_data):\n",
    "    # do: perform anomaly detection\n",
    "    if error == True:\n",
    "        # do: give warning\n",
    "        else \n",
    "        # continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#colnames = [\"time\", \"ID\", \"DLC\", \"Data1\", \\\n",
    "       # \"Data2\", \"Data3\", \"Data4\", \"Data5\", \"Data6\", \"Data7\", \"Data8\", \"Attack\"]\n",
    "\n",
    "nRows = 100000 #number of rows that you want\n",
    "df = pd.read_csv('gear_dataset.csv', nrows = nRows, sep=',')\n",
    "df = df.to_numpy()\n",
    "df = df[:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this uses csv while output from simulator is .log\n",
    "# how to do set amount at same time? \n",
    "# need to divide into windows?\n",
    "\n",
    "def csv_process(filename, callback, delay=1):\n",
    "    class waiter:     # wrapper around a file object to wait for new lines on EOF\n",
    "        def __init__(self, fd, delay=1):  \n",
    "            self.fd = fd\n",
    "            self.delay = delay\n",
    "        def __iter__(self):\n",
    "            return self\n",
    "        #def next(self):  # try to read a line of wait delay seconds\n",
    "        def __next__(self):\n",
    "            while True:\n",
    "                line = fd.readline()\n",
    "                if line:\n",
    "                    return line\n",
    "                time.sleep(self.delay)\n",
    "       # def __next__(self):  # ensure compatibility with Python3.x\n",
    "        #    return self.next()\n",
    "    with open(filename, \"rb\") as fd:\n",
    "        rows = csv.reader(waiter(fd, delay), delimiter=',')\n",
    "        rows = process_data(rows)\n",
    "\n",
    "        for row in rows:\n",
    "            error = evaluate(row)\n",
    "            if error >= threshold:\n",
    "                print('Anomaly detected')\n",
    "                break   \n",
    "\n",
    "def process_data(data):\n",
    "    rows = rows.to_numpy()\n",
    "    rows = rows[:,2:3] # anpassas till datan\n",
    "    rows = format(int(data, base=16), \"064b\") # to binary\n",
    "    return rows\n",
    "\n",
    "def evaluate(row):\n",
    "    predicted = model.predict(data)\n",
    "    error = data-predicted\n",
    "    error = np.sum(error,axis=1)\n",
    "    error = np.abs(error)\n",
    "    return error\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}